{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0f769b",
   "metadata": {
    "id": "5b0f769b"
   },
   "source": [
    "### Algorithm: CNN-LSTM including normalization\n",
    "### Created: Julio 31 ,2024\n",
    "### Dataset : ArticullaryWord Recognition\n",
    "### Authors: Edgar Acuna and Roxana Aparicio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a16dfa",
   "metadata": {
    "id": "d8a16dfa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score, ConfusionMatrixDisplay\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# cnn lstm model\n",
    "from numpy import mean\n",
    "from numpy import std, unique\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "#from keras.models import Sequential\n",
    "##from keras.layers import Dense\n",
    "#from keras.layers import Flatten\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import LSTM\n",
    "#from keras.layers import TimeDistributed\n",
    "#from keras.layers.convolutional import Conv1D\n",
    "#from keras.layers.convolutional import MaxPooling1D\n",
    "#from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score, ConfusionMatrixDisplay\n",
    "import tensorflow.keras.layers as layers\n",
    "import keras\n",
    "from numpy import mean\n",
    "from numpy import std, unique\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "#from keras.layers import TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D, LSTM, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load a single file as a numpy array\n",
    "#def load_file(filepath):\n",
    "#    dataframe = read_csv(filepath, header=None)\n",
    "#    return dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def load_data(dataset, split=\"Train\"):\n",
    "    if split==\"Train\":\n",
    "        X, y, meta_data = load_classification(dataset, split=\"Train\")\n",
    "    else:\n",
    "        X, y, meta_data = load_classification(dataset, split=\"Test\")\n",
    "    print(\" Shape of X = \", X.shape)\n",
    "    print(\" Shape of y = \", y.shape)\n",
    "    #Swap dimensions so features are the third dimension\n",
    "    X = X.swapaxes(1, 2)\n",
    "    print(\" New shape of X = \", X.shape)\n",
    "    #prepare y\n",
    "    y = pd.DataFrame(y)\n",
    "    enc = preprocessing.OneHotEncoder(dtype=int)\n",
    "    enc.fit(y)\n",
    "    y = enc.transform(y).toarray()\n",
    "    print(\" New shape of y = \", y.shape)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Training data\n",
    "X, y = load_data(\"ArticularyWordRecognition\",split=\"Train\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0361a2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# loading Testing data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Xt, yt \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticularyWordRecognition\u001b[39m\u001b[38;5;124m\"\u001b[39m,split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "# loading Testing data\n",
    "Xt, yt = load_data(\"ArticularyWordRecognition\",split=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1695c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 144, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Boxlots before normalization\n",
    "import numpy as np\n",
    "Xb= np.concatenate((X, Xt),axis=0)\n",
    "print(Xb.shape)\n",
    "tempo1=X.reshape(Xb.shape[2],-1).T\n",
    "pyplot.boxplot(tempo1)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e931a21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82800, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#print(tempo.shape)\n",
    "X = scaler.fit_transform(X.reshape(X.shape[2], -1)).reshape(X.shape)\n",
    "Xb = scaler.fit_transform(Xb.reshape(Xb.shape[2], -1)).reshape(Xb.shape)\n",
    "Xt = scaler.fit_transform(Xt.reshape(Xt.shape[2], -1)).reshape(Xt.shape)\n",
    "tempo=Xb.reshape(Xb.shape[2],-1).T\n",
    "X1 = scaler.fit_transform(tempo)\n",
    "#print(X)\n",
    "tempodf=pd.DataFrame(X1)\n",
    "print(tempodf.shape)\n",
    "pyplot.boxplot(tempodf)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee3cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 144, 9)\n",
      "(300, 144, 9)\n"
     ]
    }
   ],
   "source": [
    "Xn1=Xb[0:275]\n",
    "print(Xn1.shape)\n",
    "Xn2=Xb[275:575]\n",
    "print(Xn2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cVU3x0g5GLhi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVU3x0g5GLhi",
    "outputId": "6970e28b-a434-4358-e517-512d6aae333f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(275, 144, 9)\n",
      "(275, 2, 72, 9)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_63 (TimeDi  (None, None, 71, 32)     608       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_64 (TimeDi  (None, None, 35, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_65 (TimeDi  (None, None, 34, 64)     4160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_66 (TimeDi  (None, None, 17, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_67 (TimeDi  (None, None, 16, 128)    16512     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_68 (TimeDi  (None, None, 8, 128)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_69 (TimeDi  (None, None, 1024)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, None, 64)          278784    \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 25)                1625      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 392,505\n",
      "Trainable params: 392,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 15ms/step - loss: 3.2206 - accuracy: 0.0436\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.2062 - accuracy: 0.0655\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.1083 - accuracy: 0.1818\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.7839 - accuracy: 0.2145\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.3416 - accuracy: 0.2945\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8289 - accuracy: 0.4509\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2197 - accuracy: 0.7236\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8731 - accuracy: 0.7600\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6677 - accuracy: 0.8145\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4566 - accuracy: 0.8836\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2855 - accuracy: 0.9527\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1781 - accuracy: 0.9782\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1088 - accuracy: 0.9927\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0691 - accuracy: 0.9964\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 9.6476e-04 - accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 9.2362e-04 - accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.8740e-04 - accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.5224e-04 - accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 8.2015e-04 - accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.9000e-04 - accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.5923e-04 - accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.3124e-04 - accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.0574e-04 - accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.8059e-04 - accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.5746e-04 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.3571e-04 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.1350e-04 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.9361e-04 - accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 5.7412e-04 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.5555e-04 - accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.3858e-04 - accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.2216e-04 - accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.0570e-04 - accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.9046e-04 - accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.7637e-04 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.6232e-04 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.4960e-04 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.3668e-04 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.2465e-04 - accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.1317e-04 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.0211e-04 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 3.9045e-04 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.8049e-04 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.6989e-04 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.6127e-04 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.5152e-04 - accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.4278e-04 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.3356e-04 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.2526e-04 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.1732e-04 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.0966e-04 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.0232e-04 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.9498e-04 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.8777e-04 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.8145e-04 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.7490e-04 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.6874e-04 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.6288e-04 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.5698e-04 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.5128e-04 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.4583e-04 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.4048e-04 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.3510e-04 - accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.3019e-04 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.2531e-04 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.2063e-04 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.1617e-04 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.1179e-04 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.0738e-04 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.0320e-04 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.9916e-04 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.9535e-04 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.9132e-04 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8751e-04 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8407e-04 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8033e-04 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.7673e-04 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7328e-04 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.7000e-04 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6677e-04 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6344e-04 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6017e-04 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.5704e-04 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5377e-04 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5051e-04 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.4738e-04 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.4412e-04 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4125e-04 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3847e-04 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3541e-04 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3279e-04 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.3024e-04 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.2777e-04 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2529e-04 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.2298e-04 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2073e-04 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1849e-04 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1650e-04 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1446e-04 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1249e-04 - accuracy: 1.0000\n",
      "Epoch 135/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1052e-04 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0865e-04 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0684e-04 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0508e-04 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0331e-04 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0165e-04 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.9985e-05 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.8382e-05 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.6752e-05 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 9.5220e-05 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.3742e-05 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 9.2273e-05 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 9.0837e-05 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 8.9398e-05 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 8.8053e-05 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 8.6770e-05 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 8.5407e-05 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.4127e-05 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.2893e-05 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.1674e-05 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.0472e-05 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.9260e-05 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.8186e-05 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.7024e-05 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.5893e-05 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.4775e-05 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.3675e-05 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.2645e-05 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.1545e-05 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.0576e-05 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.9589e-05 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 6.8582e-05 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 6.7683e-05 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.6739e-05 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.5806e-05 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 6.4916e-05 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 6.4023e-05 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 6.3149e-05 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.2264e-05 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 6.1473e-05 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.0645e-05 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5.9870e-05 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 5.9048e-05 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5.8282e-05 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.7481e-05 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5.6705e-05 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 5.5977e-05 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 5.5227e-05 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5.4502e-05 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 5.3816e-05 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 5.3093e-05 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.2420e-05 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5.1743e-05 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 5.1080e-05 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5.0425e-05 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 4.9805e-05 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.9171e-05 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 4.8564e-05 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.7901e-05 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.7303e-05 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 4.6710e-05 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.6132e-05 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.5550e-05 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 4.5020e-05 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.4465e-05 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.3879e-05 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.3367e-05 - accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 4.2811e-05 - accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 4.2290e-05 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 4.1792e-05 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.1268e-05 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.0775e-05 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 4.0277e-05 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.9777e-05 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.9295e-05 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.8816e-05 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.8331e-05 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.7837e-05 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.7356e-05 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.6898e-05 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.6439e-05 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.5992e-05 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.5579e-05 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.5155e-05 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 3.4766e-05 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.4356e-05 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 3.3988e-05 - accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.3600e-05 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.3242e-05 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 3.2884e-05 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.2516e-05 - accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.2157e-05 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 3.1822e-05 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 3.1469e-05 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 3.1145e-05 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 3.0796e-05 - accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 3.0471e-05 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 3.0166e-05 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.9844e-05 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.9542e-05 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.9219e-05 - accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.8913e-05 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.8608e-05 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.8328e-05 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.8041e-05 - accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.7761e-05 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.7470e-05 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.7199e-05 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.6924e-05 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.6659e-05 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.6388e-05 - accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.6119e-05 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.5845e-05 - accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.5593e-05 - accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.5339e-05 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.5090e-05 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.4819e-05 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.4581e-05 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.4321e-05 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.4096e-05 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.3857e-05 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.3619e-05 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.3396e-05 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.3172e-05 - accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.2938e-05 - accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.2719e-05 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.2507e-05 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.2289e-05 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.2088e-05 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.1871e-05 - accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.1668e-05 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.1447e-05 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.1245e-05 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.1048e-05 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.0856e-05 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.0661e-05 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.0464e-05 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 2.0267e-05 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 2.0082e-05 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.9910e-05 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.9699e-05 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.9517e-05 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.9328e-05 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.9155e-05 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.8973e-05 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.8803e-05 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.8613e-05 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.8453e-05 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8279e-05 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8107e-05 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.7951e-05 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.7779e-05 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.7611e-05 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.7453e-05 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.7295e-05 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.7136e-05 - accuracy: 1.0000\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 1.6998e-05 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.6842e-05 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.6699e-05 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.6547e-05 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.6398e-05 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.6253e-05 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6109e-05 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5964e-05 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.5829e-05 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.5695e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "import time\n",
    "verbose, epochs, batch_size = 1, 300, 32\n",
    "#trainX, trainy, testX, testy = trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "trainX=Xn1\n",
    "trainy=y\n",
    "testX=Xn2\n",
    "testy=yt\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "print(n_features)\n",
    "# reshape data into time steps of sub-sequences\n",
    "n_steps, n_length =2,72\n",
    "#For P#n_steps, n_length = 5, 20\n",
    "print(trainX.shape)\n",
    "trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "print(trainX.shape)\n",
    "testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "#print(\"number of features\",n_features)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=32, kernel_size=2, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "#model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=2, activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "#model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(Conv1D(filters=128, kernel_size=2, activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "#model.add(TimeDistributed(Dropout(0.5)))\n",
    "#model.add(TimeDistributed(Conv1D(filters=1024, kernel_size=2, activation='relu')))\n",
    "#model.add(TimeDistributed(MaxPooling1D(pool_size=3)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.summary()\n",
    "start_time=time.time()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "test_results= model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "#print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61fd15eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61fd15eb",
    "outputId": "4e9aaa61-d4de-48e6-d3a0-dc8aa5667084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results - Loss: 0.7805772423744202 - Accuracy: 0.8766666650772095%\n",
      "Training time:---  45.26172661781311 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "print(\"Training time:---  %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c25acacf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c25acacf",
    "outputId": "fe58217e-3105-42b8-e57a-6fcc228d1a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 5ms/step\n",
      "(300,)\n",
      "Rate of Probability of classification exceeding a threshold in test 0.9066666666666666\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        12\n",
      "           1       0.75      1.00      0.86        12\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       0.77      0.83      0.80        12\n",
      "           4       0.92      0.92      0.92        12\n",
      "           5       0.92      1.00      0.96        12\n",
      "           6       1.00      0.83      0.91        12\n",
      "           7       0.90      0.75      0.82        12\n",
      "           8       0.92      1.00      0.96        12\n",
      "           9       0.80      0.67      0.73        12\n",
      "          10       1.00      1.00      1.00        12\n",
      "          11       0.85      0.92      0.88        12\n",
      "          12       1.00      0.67      0.80        12\n",
      "          13       1.00      0.83      0.91        12\n",
      "          14       0.89      0.67      0.76        12\n",
      "          15       0.65      0.92      0.76        12\n",
      "          16       0.86      1.00      0.92        12\n",
      "          17       1.00      0.83      0.91        12\n",
      "          18       0.92      0.92      0.92        12\n",
      "          19       0.80      0.67      0.73        12\n",
      "          20       0.92      1.00      0.96        12\n",
      "          21       1.00      1.00      1.00        12\n",
      "          22       0.92      0.92      0.92        12\n",
      "          23       0.92      1.00      0.96        12\n",
      "          24       0.79      0.92      0.85        12\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.89      0.88      0.88       300\n",
      "weighted avg       0.89      0.88      0.88       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score\n",
    "train_features = np.array(trainX)\n",
    "test_features = np.array(testX)\n",
    "train_labels=np.array(trainy)\n",
    "#train_labels=pd.DataFrame(trainy)\n",
    "#n_values = train_labels.idxmax(axis=1)\n",
    "y_values=np.argmax(train_labels,axis=1)\n",
    "#print(y_values)\n",
    "test_labels=np.array(testy)\n",
    "yt_values=np.argmax(test_labels,axis=1)\n",
    "#train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "a=model.predict([test_features])\n",
    "predict_classes=np.argmax(a,axis=1)\n",
    "th=.8\n",
    "atempo=a.max(axis=1)\n",
    "print(atempo.shape)\n",
    "print('Rate of Probability of classification exceeding a threshold in test',(atempo[atempo>th].shape[0])/atempo.shape[0])\n",
    "#prob2=pd.DataFrame(model.predict_proba(test_features,batch_size=150))\n",
    "#a=prob2.max(axis=1)\n",
    "#print('Probability of classification',(a[a>.80].shape[0])/prob2.shape[0])\n",
    "#print('Rate of Probability of classification exceding a trhershold',(a[a>.50].shape[0])/a.shape[0])\n",
    "a1=model.predict([train_features])\n",
    "predict_classes1=np.argmax(a1,axis=1)\n",
    "#f1_train=sklearn.metrics.f1_score(ytrain, train_predictions_baseline, average=\"weighted\")\n",
    "#test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "#print(test_predictions_baseline)\n",
    "#f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=\"weighted\")\n",
    "#print('f1_scores in testing set',f1_test)\n",
    "#Calculating metrics for each class\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(yt_values, predict_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06b7c3db",
   "metadata": {
    "id": "06b7c3db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(yt_values, predict_classes)\n",
    "#print(cm)\n",
    "good=np.diag(cm)/np.unique(yt_values,return_counts=True)[1]\n",
    "#print(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f5d027a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "f5d027a2",
    "outputId": "6cd26d1b-f986-48cc-b00b-066ac3e0e6af"
   },
   "outputs": [
    {
     "ename": "PlotlyError",
     "evalue": "oops, the x list that you provided does not match the width of your z matrix ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPlotlyError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m z_text \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mstr\u001b[39m(y1) \u001b[38;5;28;01mfor\u001b[39;00m y1 \u001b[38;5;129;01min\u001b[39;00m x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m z]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# set up figure\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_annotated_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolorscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mViridis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# add title\u001b[39;00m\n\u001b[0;32m     22\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(title_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<i><b>Confusion matrix</b></i>\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m                   \u001b[38;5;66;03m#xaxis = dict(title='x'),\u001b[39;00m\n\u001b[0;32m     24\u001b[0m                   \u001b[38;5;66;03m#yaxis = dict(title='x')\u001b[39;00m\n\u001b[0;32m     25\u001b[0m                  )\n",
      "File \u001b[1;32m~\\anaconda37\\lib\\site-packages\\plotly\\figure_factory\\_annotated_heatmap.py:104\u001b[0m, in \u001b[0;36mcreate_annotated_heatmap\u001b[1;34m(z, x, y, annotation_text, colorscale, font_colors, showscale, reversescale, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Avoiding mutables in the call signature\u001b[39;00m\n\u001b[0;32m    103\u001b[0m font_colors \u001b[38;5;241m=\u001b[39m font_colors \u001b[38;5;28;01mif\u001b[39;00m font_colors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m--> 104\u001b[0m \u001b[43mvalidate_annotated_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# validate colorscale\u001b[39;00m\n\u001b[0;32m    107\u001b[0m colorscale_validator \u001b[38;5;241m=\u001b[39m ColorscaleValidator()\n",
      "File \u001b[1;32m~\\anaconda37\\lib\\site-packages\\plotly\\figure_factory\\_annotated_heatmap.py:35\u001b[0m, in \u001b[0;36mvalidate_annotated_heatmap\u001b[1;34m(z, x, y, annotation_text)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(z[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mPlotlyError(\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moops, the x list that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovided does not match the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth of your z matrix \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m         )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(z):\n",
      "\u001b[1;31mPlotlyError\u001b[0m: oops, the x list that you provided does not match the width of your z matrix "
     ]
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "# invert z idx values\n",
    "\n",
    "z= cm\n",
    "\n",
    "# invert z idx values\n",
    "#z = z[::-1]\n",
    "\n",
    "#abnormal, normal\n",
    "x= [1,2]\n",
    "y1=x\n",
    "#y =x[::-1].copy() # invert idx values of x\n",
    "#print(y)\n",
    "#y=x\n",
    "# change each element of z to type string for annotations\n",
    "z_text = [[str(y1) for y1 in x] for x in z]\n",
    "\n",
    "# set up figure\n",
    "fig = ff.create_annotated_heatmap(z, x=x, y=y1, annotation_text=z_text, colorscale='Viridis')\n",
    "\n",
    "# add title\n",
    "fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
    "                  #xaxis = dict(title='x'),\n",
    "                  #yaxis = dict(title='x')\n",
    "                 )\n",
    "\n",
    "# add custom xaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted value\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# add custom yaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.35,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Actual value\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# adjust margins to make room for yaxis title\n",
    "fig.update_layout(margin=dict(t=50, l=200))\n",
    "\n",
    "# add colorbar\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f22b31",
   "metadata": {
    "id": "e4f22b31"
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "Xt = Xt.reshape((Xt.shape[0], n_steps, n_length, n_features))\n",
    "test_results1= model.evaluate(Xt, yt, batch_size=batch_size, verbose=0)\n",
    "print(f'Test results1 - Loss: {test_results1[0]} - Accuracy: {test_results1[1]}%')\n",
    "#print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c06271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
